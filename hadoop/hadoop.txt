Hadoop是一个开源框架，允许使用简单的编程模型在跨计算机集群的分布式环境中存储和处理大数据。它的设计是从单个服务器扩展到数千个机器，每个都提供本地计算和存储。今天整理了一些关于hadoop相关概念的知识点，觉得文章有用的小伙伴可以直接收藏~
我还是要推荐下我自己创建的大数据资料分享群142973723，这是大数据学习交流的地方，不管你是小白还是大牛，小编都欢迎，不定期分享干货，包括我整理的一份适合零基础学习大数据资料和入门教程。
Hadoop介绍：

Hadoop实现了一个分布式文件系统（Hadoop Distributed File System），简称HDFS。

HDFS有高容错性的特点，并且设计用来部署在低廉的硬件上；而且它提供高吞吐量来访问应用程序的数据，适合那些有着超大数据集的应用程序。

Hadoop的框架最核心的设计就是：HDFS和MapReduce。HDFS为海量的数据提供了存储，则MapReduce为海量的数据提供了计算。

1）HDFS

HDFS自动保存多个副本，移动计算。缺点是小文件存取占用namenode内存，写入只支持追加，不能随机修改。它存储的逻辑空间称为block，文件的权限类似linux。
整体架构分三种节点，NN,SNN,DN

NN 负责读写操作保存metadata(Ownership Permission blockinfo)
SNN 负责辅助NN合并fsimage和edits，减少nn启动时间
DN 负责存数据，每个数据（文件）分割成若干block，每个block默认3个副本。启动后像NN发送心跳保持联系
NN保存的metadata在hdfs启动后加载到计算机内存，除block位置信息的metadata保存在OS文件系统中的fsimage文件中，对metadata的操作日志保存在OS文件系统中的edits文件中。block位置信息是hdfs启动后由DN上报NN再加载到内存的。

2）MapReduce

离线计算框架，过程分为split map shuffle reduce四个过程。
架构节点有：Jobtracker TaskTracker。
Split将文件分割，传输到mapper，mapper接收KV形式的数据，经过处理，再传到shuffle过程。

Shuffle先进行HashPartition或者自定义的partition，会有数据倾斜和reduce的负载均衡问题；再进行排序，默认按字典排序；为减少mapper输出数据，再根据key进行合并，相同key的数据value会被合并；最后分组形成（key,value{}）形式的数据，输出到下一阶段。
Reduce输入的数据就变成了，key+迭代器形式的数据，再进行处理。

Hadoop能解决哪些问题？

海量数据需要及时分析和处理
海量数据需要深入分析和挖掘
数据需要长期保存
海量数据存储的问题 
Hadoop 相关技术
Hbase：Nosql数据库，Key-Value存储，最大化利用内存
HDFS：hadoop distribute file system(分布式文件系统)，最大化利用磁盘
MapReduce：编程模型，主要用来做数据分析，最大化利用CPU

集中式系统
集中式系统用一句话概括就是：一个主机带多个终端。

终端没有数据处理能力，仅负责数据的录入和输出。而运算、存储等全部在主机上进行。现在的银行系统，大部分都是这种集中式的系统，此外，在大型企业、科研单位、政府等也有分布。

集中式系统的最大的特点就是部署结构非常简单，底层一般采用从IBM、HP等厂商购买到的昂贵的大型主机。因此无需考虑如何对服务进行多节点的部署，也就不用考虑各节点之间的分布式协作问题。但是，由于采用单机部署。很可能带来系统大而复杂、难于维护、发生单点故障、扩展性差等问题。

分布式系统(distributed system)

一群独立计算机集合共同对外提供服务，但是对于系统的用户来说，就像是一台计算机在提供服务一样。分布式意味着可以采用更多的普通计算机（相对于昂贵的大型机）组成分布式集群对外提供服务。计算机越多，CPU、内存、存储资源等也就越多，能够处理的并发访问量也就越大。

一个标准的分布式系统应该具有以下几个主要特征：

分布性：分布式系统中的多台计算机之间在空间位置上可以随意分布，系统中的多台计算机之间没有主、从之分，即没有控制整个系统的主机，也没有受控的从机。
透明性：系统资源被所有计算机共享。每台计算机的用户不仅可以使用本机的资源，还可以使用本分布式系统中其他计算机的资源(包括CPU、文件、打印机等)。
同一性：系统中的若干台计算机可以互相协作来完成一个共同的任务，或者说一个程序可以分布在几台计算机上并行地运行。
通信性：系统中任意两台计算机都可以通过通信来交换信息。